[БЕЗ_ЗВУКА] В этом видео мы научимся строить доверительный интервал для доли. Работать мы будем с генеральной совокупностью, состоящей из бинарных событий. Это такие события, каждое из которых можно связать с 0 или 1, или по-другому, с успехом или неудачей. В жизни довольно много примеров таких событий. Например, это проигрыш или выигрыш в лотерею, покупка или не покупка товара, клик или не клик на рекомендацию. Мы с вами рассмотрим следующий пример. Предположим, что мы работаем с некоторой рекламной сетью и у нас есть возможность откручивать баннер на нескольких рекламных площадках. В этом случае нам хочется измерять качество открутки наших баннеров и понимать, достаточно ли прекрасен каждый их тех баннеров, которые мы показываем, то есть нравятся ли они пользователям или нет. Для того чтобы это понять, мы можем померить, как часто пользователи кликают на эти баннеры, а как часто они их просто игнорируют. Такой показатель называется «click through rate», или «доля кликов по баннеру». В нашем случае это как раз и есть доля успехов в нашей генеральной совокупности. Чтобы оценить эту долю точно, нам нужно дождаться конца открутки нашего баннера, далее собрать все данные (данные с каждой из площадок, на которых мы его откручивали) и честно это метрику посчитать. Понятно, что это занимает существенное время и часто нам хочется сделать вывод о качестве баннера сильно раньше, чем заканчивается открутка. Например, это может помочь нам прекратить показывать неудачные баннеры. Таким образом, мы приходим к задаче оценки доли успехов по выборке. Ровно этим мы с вами сегодня займемся. Для начала давайте сгенерируем такие данные. Импортируем необходимые библиотеки, и теперь делаем следующее. Понятно, что в рамках предложенной задачи мы работаем с конечной генеральной совокупностью. Вот давайте такую сгенерируем. Делать это будем с помощью модуля random из библиотеки NumPy и будем использовать функцию randint. Скажем, что нам интересуют два значения: 0 и 1, и выборка размера 100 000. Дальше давайте сразу же сгенерируем случайную подвыборку из нашей генеральной совокупности. Сделаем это с помощью random.choice. Сгенерируем подвыборку размером 1000. Именно по ней мы будем оценивать долю успехов. Так, готово. Теперь давайте посмотрим истинное значение доли. Это можно сделать, оценив среднее по генеральной совокупности. В данном случае мы видим, что наше истинное значение — 0,498. Теперь давайте попробуем получить оценку истинного значения доли по нашей выборке. Из предыдущих уроков вы знаете, что самая лучшая оценка среднего — это выборочное среднее. Почему она лучшая? Эта оценка является несмещенной, асимптотически нормальной, эффективной. Вот давайте эту оценку и посчитаем. Это делается очень просто, с помощью метода mean. Видим, что мы получили 0,502. В общем-то, очень хорошее приближение. Однако часто такой оценки недостаточно, например, в тех случаях, когда мы хотим знать, в каких диапазонах меняется настоящая доля, то есть какое минимальное и максимальное значение на нашу оценку среднего. Для того чтобы такую оценку получить, нужно построить доверительный интервал на среднее. Для того чтобы такой интервал получить, мы с вами будем использовать библиотеку StatsModels. Чаще всего доверительные интервалы строятся на основе нормального распределения с использование центральной предельной теоремы, формула прямо перед вами. Давайте и мы начнем с этого. Для того чтобы такие интервалы получить, мы будем использовать функцию propotion_confint. Она принимает несколько аргументов. Первый аргумент — это количество успехов в нашей подвыборке, второй аргумент — это количество событий, то есть размер нашей подвыборки, и метод, с помощью которого мы хотим это оценивать. Мы работаем с нормальным распределением, поэтому пишем метод normal. Итак, давайте построим интервал, очень просто. И теперь давайте выведем заданные границы на экран. Помимо самих границ интервала нас также будет интересовать его ширина. Понятно: это довольно важная характеристика, потому что чем уже получился наш интервал, тем более точную оценку диапазона мы с вами получили. Давайте посмотрим. Видим, что интервал получился неплохой. Помним: наше настоящее среднее — 0,498, оно в этот интервал попадает. Ширина интервала — 0,06. В общем-то, довольно узкий интервал. Теперь давайте попробуем эту оценку улучшить. Следующий метод, который очень часто используют, — это доверительный интервал Уилсона. Это некоторое улучшение предыдущего метода, которое позволяет получать качественные оценки в крайних случаях, то есть тогда, когда наша доля очень близка к 0 или очень близка к 1. Более того, этот интервал получается неплохим в случае, когда наша случайная подвыборка довольно мала, то есть включает в себя очень мало событий. Формула для расчета перед вами, и давайте строить интервал. Это делается с помощью той же самой функции. Видите, что первые два параметра не меняются, однако нам нужно изменить метод, с помощью которого мы будем строить интервал. В данном случае мы будем пользоваться методом Уилсона, поэтому давайте это явно напишем. Итак, получаем интервал. Теперь давайте выведем результат на экран и сравним с предыдущим. Видим, что наши границы практически не изменились, видим, что изменения у нас только в пятом знаке после запятой, ну и с данной точностью мы даже не можем увидеть разницу в ширине интервала, то есть фактически они одинаковые. Почему так получается? Здесь мы не видим явных преимуществ, потому что наша случайная подвыборка довольно хороша. Значение доли у нас не является крайним, событий целых 1000, поэтому, в общем-то, мы и так можем довольно неплохо это оценить. Теперь давайте посмотрим еще раз на ширину интервала. В данном случае наш интервал имеет ширину 0,06. Часто мы с вами можем хотеть задать некоторые ограничения на ширину интервала. Например, мы хотим знать более точную оценку и получить интервал меньшей ширины. Таким образом, возникает вопрос: сколько же событий нам нужно знать для того, чтобы оценить долю с достаточной точностью? Для того чтобы этот вопрос решить, существует очень удобный метод под названием samplesize_ confint_proportion. Он позволяет нам явно задать ограничение на ширину нашего интервала и получить количество событий, которое необходимо для того, чтобы получить оценку заданной ширины. Давайте это сделаем. Сначала импортируем нужную функциональность, и вот давайте для разнообразия получим интервал в три раза уже, то есть интервал шириной 0,02. Для этого сначала указываем среднее выборочное по нашей выборке и давайте теперь укажем ширину интервала. На самом деле нам нужно указать половину ширины этого интервала для того, чтобы в дальнейшем получить интервал заданной ширины. Давайте получим количество объектов n_samples и сразу же на него посмотрим. Оказывается, что чтобы получить оценку заданной точности, то есть чтобы получить ширину в три раза уже, нам нужно взять почти в 10 раз больше событий. Давайте это сделаем. Перегенерируем нашу случайную выборку. Снова будем использовать метод random.choice, однако теперь скажем, что количество объектов будет равняться переменной n_samples, тому количеству, которое мы рассчитали шагом выше. Итак, перестраиваем выборку. Теперь давайте снова получим интервал на долю с помощью метода proportion_confint. Итак, получили наш интервал и теперь смотрим. Нас интересует, получился ли у нас интервал заданной ширины. Итак, мы видим, что всё получилось. Интервал по-прежнему достаточно хороший, наше истинное значение входит в заданный интервал и при этом он стал в три раза уже. Мы получили оценку интервала шириной 0,02. А на этом мы с вами заканчиваем. Мы научились строить доверительные интервалы на долю с помощью нормального распределения, а также с помощью метода Уилсона. В следующем уроке мы с вами продолжим строить интервальные оценки и научимся делать это с помощью такого понятия, как bootstrap.

В этом видео мы потренируемся строить биномиальный критерий для доли. Ранее мы уже научились строить доверительный интервал для доли с помощью нормального распределения, а также методом Уилсона. В этом видео мы потренируемся строить критерий. Давайте рассмотрим следующую задачу. Наверняка многие помнят, что Джеймс Бонд утверждает, что он предпочитает пить мартини взболтанным, но не смешанным. Как бы мы могли проверить это на практике? Можно было бы предложить Джеймсу Бонду пройти так называемый blind test, или слепое тестирование. Можно было бы завязать ему глаза, несколько раз предложить на выбор взболтанный и смешанный мартини, а после этого спросить, какой напиток он предпочитает. В данном случае, если бы Джеймс Бонд выбирал взболтанный напиток, мы бы говорили, что это успех, потому что его выбор соответствует его утверждению. В противном случае мы бы говорили, что произошла неудача, так как выбор утверждению не соответствует. Как в данном случае выглядела бы проверка гипотез? Мы бы проверяли нулевую гипотезу о том, что Джеймс Бонд не различает два вида напитков и выбирает наугад, против некоторой альтернативы. Ну, альтернатива, вообще говоря, могла бы быть разной. С одной стороны, мы могли бы рассматривать двухстороннюю альтернативу — Джеймс Бонд отличает два вида напитков, и у него есть некоторые предпочтения — или одну из односторонних — Джеймс Бонд предпочитает взболтанный мартини, так как он утверждает, или Джеймс Бонд предпочитает смешанный. Такой эксперимент мы провели бы n раз, и в качестве T-статистики использовали бы количество единиц выборки или сумму элементов выборки. Если наша нулевая гипотеза справедлива, то есть Джеймс Бонд выбирает напиток наугад, то мы могли бы равновероятно получить любую комбинацию из 0 и 1. Таких комбинаций — ровно 2 в степени n, поэтому, для того чтобы получить нулевое распределение, мы могли бы с вами сгенерировать все эти наборы данных, на каждом посчитать значение этой статистики и таким образом получить наше распределение. На самом деле, в данном случае этот шаг мы можем пропустить. Почему? Потому что мы имеем дело с выборкой, состоящей из 0 и 1 из распределения Бернулли с вероятностью успеха p. В данном случае вероятность успеха p = 0.5, потому что если нулевая гипотеза справедлива, то успех и неудача происходят равновероятно. Соответственно, мы с вами работаем с выборкой, которая представляет из себя сумму n независимых, одинаково распределенных величин из распределения Бернулли. Соответственно, нулевое распределение статистики — это биномиальное распределение с параметрами n — количество экспериментов, и p — вероятность успеха. Соответственно, давайте возьмем n = 16, и вероятность успеха — 0.5. Вот давайте посмотрим, как распределение нулевой статистики могло бы выглядеть. Давайте для начала его построим. Это можно сделать с помощью функции binom, которой мы передаем количество испытаний и вероятность успеха, и дальше давайте просто посмотрим распределение. Видим, что получили распределение ровно такое, которое мы ожидаем — пик в центре. Так как у нас 16 испытаний, вероятность успеха — 0.5, то пик должен приходиться на 8. Ровно это мы здесь и видим. Теперь давайте перейдем непосредственно к проверке гипотез. Так как Джеймс Бонд утверждает, что он предпочитает взболтанный мартини, то давайте с этого и начнем, и будем тестировать гипотезу H0 против односторонней альтернативы. Соответственно, гипотеза H1 — Джеймс Бонд предпочитает взболтанный мартини. При такой альтернативе более вероятно попасть в правый конец распределения, то есть более вероятно в нашей выборке получить много единиц. А вот давайте предположим, что мы действительно провели 16 испытаний, и при этом в 12 из 16 испытаний Джеймс Бонд выбрал взболтанный мартини, то есть произошел успех. Давайте построим соответствующее нулевое распределение, и видим, что в данном случае наша T-статистика была бы равна 12, и нас бы интересовал правый хвост из нашего распределения. В данном случае нам нужно просуммировать высоту столбцов, начиная со столбца, соответствующего 12, и правее, то есть правый хвост нашего распределения, и использовать полученное значение при расчете достигаемого уровня значимости. Итак, давайте это сделаем, в данном случае передаем в метод binom_test из модуля stats следующие параметры. Первый параметр — это 12, количество успеха, соответственно, следующий параметр — 16, количество испытаний, а величина 0.5 — это величина p. И соответственно, вид альтернативы, в данном случае — односторонняя альтернатива greater. Итак, давайте посмотрим на значение p-value, и видим, что p-value достаточно маленькое — 0.04. Это говорит о том, что на уровне значимости 0.05 мы можем отвергать нулевую гипотезу, то есть если 12 раз от 16 у нас произойдет успех, то мы с вами можем сделать вывод о том, что Джеймс Бонд предпочитает взболтанный мартини. Так, давайте посмотрим, что было бы, если успеха было немножечко меньше, например 11. Могли бы мы в этом случае прийти к такому же выводу? Давайте построим соответствующую гистограмму и увидим, что добавился еще один столбец по сравнению с предыдущим рисунком. Но теперь давайте рассчитаем значения p-value. Как вы думаете: мы получим значение больше или меньше? Давайте посмотрим. Видим, что значение p-value стало больше — теперь это 0.1, то есть на уровне значимости 0.05 мы уже не можем отвергнуть нулевую альтернативу. Теперь давайте перейдем к двухсторонней альтернативе. В данном случае гипотеза H1 переформулируется следующим образом: Джеймс Бонд предпочитает какой-то один определенный вид мартини, при этом мы не выбираем, какой именно. При такой альтернативе будут очень вероятны либо большие значения этой статистики, либо очень очень маленькие. При расчете достигаемого уровня значимости мы с вами будем учитывать, как правый, так и левый конец нашего распределения, соответственно, мы будем суммировать высоту правых и левых столбцов. Вот давайте для начала предположим снова, что у нас произошло 12 успехов, то есть 12 раз Джеймс Бонд выбрал взболтанный мартини, и посмотрим, какие столбцы мы с вами будем суммировать. Видим, что мы снова суммируем тот же самый правый конец, но теперь к нему добавляется и левый конец. Теперь давайте рассчитаем значение p-value, делаем мы это с помощью той же самой функции, однако теперь меняем вид альтернативы — она двухсторонняя. И смотрим на значение p-value. Видим, что значение p-value — почти 0.08, то есть это больше, чем было в том случае, когда мы проверяли гипотезу H0 против односторонней альтернативы greater. Соответственно, в данном случае мы не можем отвергнуть гипотезу на уровне значимости 0.05, однако мы можем отвергнуть нулевую гипотезу на уровне значимости 0.1. Итак, давайте посмотрим, что было бы, если бы у нас произошло 13 испытаний, может быть, их достаточно, для того чтобы отвергнуть нулевую гипотезу на уровне 0.05. Смотрим и видим, что мы суммируем значения, соответствующие правому левому концу, в данном случае столбцов — красных столбцов уже меньше, то есть мы видим, что значение статистики более экстремальное. И давайте посмотрим на значение p-value. Видим, что всего лишь 0.02, соответственно, мы можем отвергнуть нулевую гипотезу на уровне значимости 0.05. Итак, мы с вами научились применять биномиальный критерий для доли, мы научились тестировать нулевую гипотезу против двухсторонних и односторонних альтернатив, а на следующем видео мы поговорим про критерий хи-квадрат, или критерий согласия Пирсона.

[БЕЗ_ЗВУКА] В этом видео мы научимся строить интервальные оценки с помощью методологии Bootstrap. Часто нам требуется интервально оценить некоторую не самую удобную статистику, про распределение которой нам просто ничего не известно. Таких примеров довольно много. Например, это все квантили, в частности медиана, либо это может быть отношение каких-то известных нам статистик, например отношение долей. В принципе, это может быть любая функция, которую вы можете посчитать по выборке. Возникает вопрос: что делать в этом случае? В целом, чтобы построить доверительный интервал для некоторой статистики, нам нужно знать ее выборочное распределение. Если этого распределения нет, то кажется, что мы можем поступить следующим образом: нагенерировать много-много выборок из генеральной совокупности, дальше на каждой из этих выборок посчитать статистику, и таким образом по полученным данным эмпирически оценить распределение. Здесь есть следующая проблема: в том случае если мы действительно можем неограниченно генерировать выборки из генеральной совокупности, если нам это не сложно, то получается, что в целом и оценить эту статистику по всей совокупности мы тоже можем. Тогда нам уже не нужно генерировать никакие выборки, получается, что мы напрямую можем оценить значения нашей статистики. На самом деле это скорее теоретический способ, чем практический, на практике он не применим — мы практически никогда не можем неограниченно генерировать подвыборки. Тогда можно предложить другую идею: использовать так называемый параметрический подход. В этом случае мы можем сделать предположение о том, что наша статистика распределена по некоторому закону. И дальше, исходя из этого, оценить параметры распределения в соответствии с нашими предположениями. В целом такой метод может работать, но только в том случае, если мы можем на основе некоторых известных нам знаний сделать хорошие предположения. Обычно для анализ нам доступна только выборка, поэтому не всегда мы это можем. Как же поступать в этом случае? Так как для анализа нам доступна только исходная выборка, давайте поступать следующим образом: будем генерировать на основе данной выборки так называемые псевдовыборки, то есть генерировать выборки такой же длины с помощью сэмплирования с возвращением. После того как мы сгенерируем n подобных выборок, давайте просто оценим значение нашей статистики на каждой из них и таким образом оценим эмпирическое распределение. Таким образом, мы будем строить оценку не теоретической функции распределения, а эмпирической. Ровно в этом и состоит идея Bootstrap'а, давайте потренируемся применять эту идею на практике. Давайте рассмотрим следующую задачу: компания Verizon является основной телекоммуникационной региональной компанией на западе США. Это означает, что данная компания должна предоставлять услуги по ремонту оборудования не только для своих клиентов, но также для клиентов других локальных компаний. При этом, в тех случаях когда время ремонта оборудования для клиентов других компаний существенно выше, чем время ремонта оборудования для своих клиентов, компания может быть оштрафована. Давайте проанализируем данные и проверим, правда ли что время ремонта оборудования для своих клиентов существенно ниже, чем для клиентов других компаний. Для этого для начала давайте загрузим данные, сразу же выведем их размер — видим, что у нас доступны данные приблизительно о 1700 случаях ремонта оборудования, и видим, что у нас есть всего два столбца. Вот давайте посмотрим. Видим, что в первом столбце у нас отложено время, то есть время ремонта оборудования, а в следующем столбце у нас отмечена группа. Как видно из описания задачи, ILEC — это означает, что клиент является клиентом компаний Verizon, CLEC — это значит, что клиент внешний по отношению к компании. Ну и давайте теперь посмотрим, как много данных у нас есть относительно клиентов компании Verizon и как много данных относительно клиентов внешних компаний. Итак, видим, что практически все данные — это данные по клиентам компании Verizon. Ну ничего, в таких условиях мы также можем сравнивать среднее время. Для начала давайте построим гистограммы отдельно для клиентов компании Verizon и отдельно для других клиентов. Это делается очень просто: будем использовать pylab и метод hist. Теперь давайте попробуем эти диаграммы, гистограммы проанализировать. Вообще говоря, судя по тому, что мы видим, кажется, что все-таки время время ремонта оборудования для внутренних клиентов сильно меньше — мы видим, что основная часть значения сосредоточена в районе нуля. Однако оценивать такие вещи глазами не совсем правильно, давайте сделаем это строго. Будем пользоваться методологией Bootstrap. Реализация очень простая: для начала давайте сгенерируем вспомогательную функцию, для того чтобы получать эти самые псевдоподвыборки. Ну это очень просто — будет пользоваться методом randint из библиотеки numpy. Что нам хочется сделать? Нам хочется сгенерировать заданное количество выборок, количество выборок мы будем определять с помощью аргумента n_samples, исходя из исходной выборки, которую мы будем передавать в виде аргумента data. Подвыборки мы будем задавать с помощью индексов, то есть мы просто будем генерировать n_samples наборов индексов из исходного доступного диапазона. А далее, чтобы получить непосредственно выборки, мы просто применим полученный набор индексов к исходным данным. Таким образом, вернется набор подвыборок. Далее по полученным подвыборкам мы с вами сможем рассчитывать статистику, но для этого нужен просто метод, который статистику по данным умеет считать. И после того как мы с вами набор статистик получим, нам нужно просто оценить его интервально, будем это делать с помощью функции percentile. Итак, вспомогательная работа проведена, теперь давайте строить интервальные оценки. Для начала нам нужно разделить данные — делить данные про внутренних и внешних клиентов. Вот давайте это сделаем с помощью очень простого условия. Итак, данные мы отделили, теперь нам нужно научиться рассчитывать значения статистики. Так как статистика стандартная, это медиана, давайте использовать готовую реализацию — будем пользоваться функцией np. median — и посчитаем наши статистики. Несмотря на то что у нас доступно больше данных про клиентов внутренних компаний, чем внешних, давайте будем строить одинаковое количество подвыборок для одних или других клиентов. Соответственно, что мы с вами делаем? Мы с вами применяем функцию get_bootstrap_samples к наборам данных, получаем псевдоподвыборки. Далее для каждой из этих подвыборок считаем статистику этой медианы и записываем все это в список. После этого что мы можем сделать? Мы можем применить функцию stat_invervals, которой мы определили шагом ранее, к полученным данным, и получить интересующие нас доверительные интервалы. Вот в данном случае давайте получим 95-процентные доверительные интервалы. Итак, применяем, и что мы видим? Мы видим, что весь интервал для медианы времени ремонта оборудования внутренних клиентов находится левее интервала медианы времени ремонта оборудования для внешних клиентов — значит, что действительно внутренним клиентам оборудование ремонтируют быстрее. Теперь давайте немного усложним и попробуем оценить медиану разности во времени ремонта оборудования. Казалось бы, получить точечную оценку довольно просто — мы можем независимо оценить медиану по одной и по другой выборке, а дальше посчитать их разность. Вот давайте с этого начнем. Считаем медиану и оцениваем разность. Видим, что мы получили довольно большое значение для разности. Что если мы хотим оценить медиану разности во времени ремонта интервально? Кажется, что если мы будем действовать независимо, то есть интервально оценим медиану для одной выборки, а потом — для другой, то у нас нет никаких технических оснований, чтобы из этих двух интервальных оценок получить одну То есть, скажем, мы не можем просто взять и посчитать разность левых и правых границ этих интервалов — этой статистикой мы никак не сможем воспользоваться. Давайте тогда поступим чуть более хитро. Что если сначала мы сгенерируем подвыборки из исходных выборок с помощью технологии Bootstrap? То есть получим тысячу подвыборок для одной группы, тысячу подвыборок для другой группы, и дальше посчитаем для них медианы времени ремонта. После этого мы получим два набора медиан, и что мы сможем с ними сделать? Мы с ними сможем посчитать разность и интервально оценить полученную статистику. Вот давайте так поступим. Для этого пользуемся простой комбинацией функций zip и map, то есть сначала объединяем оценки медиан по подвыборкам из одной и другой исходной выборки — мы с вами получили их чуть ранее, не будем их просто перегенерировать, и дальше на основе этих данных просто посчитаем их разности. Итак, считаем дельта медиан, и теперь так как дельта медиан у нас уже есть, вот эту выборку мы можем оценить, вот ее мы можем оценить интервально. Давайте это сделаем и выведем 95-процентный доверительный интервал. Что мы видим? Видим оценку от 2 до 16.6. Таким образом, мы смогли интервально оценить разность медиан. А на этом мы заканчиваем. Мы научились строить интервальные оценки на основе методологии Bootsrap, а на следующем занятии мы перейдем к очень интересной теме — «Проверка статистических гипотез».